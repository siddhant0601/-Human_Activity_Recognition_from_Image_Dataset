{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.9.0.80)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.24.0)\n",
      "Collecting mahotas\n",
      "  Using cached mahotas-1.4.18-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image) (0.4)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl (45.5 MB)\n",
      "Using cached mahotas-1.4.18-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: opencv-contrib-python, mahotas\n",
      "Successfully installed mahotas-1.4.18 opencv-contrib-python-4.10.0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\siddh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python opencv-contrib-python scikit-image mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file containing labels\n",
    "df = pd.read_csv('label.csv')\n",
    "allClasses=df['label'].unique()\n",
    "imagesPerClass = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>hog_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>[0.2602150976933022, 0.155749659652248, 0.0978...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>using_laptop</td>\n",
       "      <td>[0.15454383002193137, 0.0719306605013999, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>hugging</td>\n",
       "      <td>[0.005943894256425121, 0.0, 0.0016811870981394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>[0.08655324940988982, 0.13651734151945993, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>using_laptop</td>\n",
       "      <td>[0.12369862424069092, 0.07044763837149698, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>Image_12596.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>[0.15301149047520893, 0.05533839192311787, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>Image_12597.jpg</td>\n",
       "      <td>clapping</td>\n",
       "      <td>[0.24126482758151405, 0.043683636772690375, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>Image_12598.jpg</td>\n",
       "      <td>sitting</td>\n",
       "      <td>[0.02833319162984024, 0.026214920858776514, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>Image_12599.jpg</td>\n",
       "      <td>dancing</td>\n",
       "      <td>[0.10675965264418201, 0.00876285842280374, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>Image_12600.jpg</td>\n",
       "      <td>listening_to_music</td>\n",
       "      <td>[0.013054837898382006, 0.0, 0.0015385273745420...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename               label  \\\n",
       "0          Image_1.jpg             sitting   \n",
       "1          Image_2.jpg        using_laptop   \n",
       "2          Image_3.jpg             hugging   \n",
       "3          Image_4.jpg            sleeping   \n",
       "4          Image_5.jpg        using_laptop   \n",
       "...                ...                 ...   \n",
       "12595  Image_12596.jpg             sitting   \n",
       "12596  Image_12597.jpg            clapping   \n",
       "12597  Image_12598.jpg             sitting   \n",
       "12598  Image_12599.jpg             dancing   \n",
       "12599  Image_12600.jpg  listening_to_music   \n",
       "\n",
       "                                            hog_features  \n",
       "0      [0.2602150976933022, 0.155749659652248, 0.0978...  \n",
       "1      [0.15454383002193137, 0.0719306605013999, 0.07...  \n",
       "2      [0.005943894256425121, 0.0, 0.0016811870981394...  \n",
       "3      [0.08655324940988982, 0.13651734151945993, 0.0...  \n",
       "4      [0.12369862424069092, 0.07044763837149698, 0.0...  \n",
       "...                                                  ...  \n",
       "12595  [0.15301149047520893, 0.05533839192311787, 0.1...  \n",
       "12596  [0.24126482758151405, 0.043683636772690375, 0....  \n",
       "12597  [0.02833319162984024, 0.026214920858776514, 0....  \n",
       "12598  [0.10675965264418201, 0.00876285842280374, 0.2...  \n",
       "12599  [0.013054837898382006, 0.0, 0.0015385273745420...  \n",
       "\n",
       "[12600 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "filename    0\n",
      "label       0\n",
      "dtype: int64\n",
      "No missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 2: Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\siddh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skimage\\feature\\texture.py:360: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gabor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import cv2\n",
    "from skimage import filters\n",
    "# https://github.com/henrhoi/image-classification/blob/master/feature_extraction_and_exploratory_data_analysis.ipynb\n",
    "# https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "# https://medium.com/@girishajmera/hog-histogram-of-oriented-gradients-an-amazing-feature-extraction-engine-for-medical-images-5a2203b47ccd\n",
    "# https://www.geeksforgeeks.org/hog-feature-visualization-in-python-using-skimage/\n",
    "# Load Dataset\n",
    "\n",
    "def preprocess_image(image, target_size=(170, 170)):\n",
    "    image_resized = np.array(Image.fromarray(image).resize(target_size))\n",
    "    return image_resized\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image_gray = rgb2gray(image)\n",
    "    features, _ = hog(image_gray, block_norm='L2-Hys', pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True)\n",
    "    return features\n",
    "# https://www.geeksforgeeks.org/visualizing-colors-in-images-using-histogram-in-python/\n",
    "# https://stackoverflow.com/questions/57385640/how-to-extract-color-features-via-histogram-from-a-masked-image\n",
    "def extract_color_histogram(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    hist = cv2.calcHist([image_rgb], [0, 1, 2], None, [16, 16, 16], [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "# https://thepythoncode.com/article/sift-feature-extraction-using-opencv-in-python\n",
    "# https://www.geeksforgeeks.org/sift-interest-point-detector-using-python-opencv/\n",
    "def extract_sift_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is not None:\n",
    "        return descriptors.flatten()[:128]  \n",
    "    return np.zeros(128)  \n",
    "# https://www.geeksforgeeks.org/create-local-binary-pattern-of-an-image-using-opencv-python/\n",
    "\n",
    "def extract_lbp_features(image):\n",
    "    image_gray = rgb2gray(image)\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method='uniform')  \n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist\n",
    "# https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
    "def extract_canny_edges(image):\n",
    "    edges = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "    return edges.flatten()\n",
    "\n",
    "hogFeatures=[]\n",
    "histoFeatures=[]\n",
    "lbpFeatures=[]\n",
    "siftFeatures=[]\n",
    "image_labels = []\n",
    "cany=[]\n",
    "def extract_combined_features(image):\n",
    "    processed_image = preprocess_image(image)\n",
    "    chog_features = extract_hog_features(processed_image)\n",
    "    ccolor_histogram = extract_color_histogram(processed_image)\n",
    "    clbp_features = extract_lbp_features(processed_image)\n",
    "    hogFeatures.append(chog_features)\n",
    "    histoFeatures.append(ccolor_histogram)\n",
    "    lbpFeatures.append(clbp_features)\n",
    "    cany.append(extract_canny_edges(processed_image))\n",
    "    siftFeatures.append(extract_sift_features(processed_image))\n",
    "for idx, row in df.iterrows():\n",
    "    image_name = row['filename']\n",
    "    label = row['label']\n",
    "    image_path = os.path.join('data', image_name)\n",
    "    image = np.array(Image.open(image_path))\n",
    "    extract_combined_features(image)\n",
    "    image_labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gabor\n",
    "from skimage import filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import cv2\n",
    "def extract_sobel_edges(image):\n",
    "    image_gray = rgb2gray(image)\n",
    "    edge_sobel = filters.sobel(image_gray)\n",
    "    return edge_sobel.flatten()\n",
    "sobelEdgeFeatures = []\n",
    "for idx, row in df.iterrows():\n",
    "    image_name = row['filename']\n",
    "    label = row['label']\n",
    "    image_path = os.path.join('data', image_name)\n",
    "    image = np.array(Image.open(image_path))\n",
    "    processed_image = preprocess_image(image)\n",
    "    csobel_edge = extract_sobel_edges(processed_image)\n",
    "    sobelEdgeFeatures.append(csobel_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogFeatures_np = np.array(hogFeatures)\n",
    "histoFeatures_np = np.array(histoFeatures)\n",
    "lbpFeatures_np = np.array(lbpFeatures)\n",
    "cannyFeatures_np=np.array(cany)\n",
    "siftFeatures_np=np.array(siftFeatures)\n",
    "df['hog_features'] = list(hogFeatures_np)\n",
    "df['color_histogram'] = list(histoFeatures_np)\n",
    "df['lbp_features'] = list(lbpFeatures_np)\n",
    "df['cany_features'] = list(cannyFeatures_np)\n",
    "df['sift_features'] = list(siftFeatures_np)\n",
    "df['label']=list(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA with 50 components\n",
      "Perceptron Model Accuracy with 50 PCA components: 0.1357142857142857\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Applying PCA with 100 components\n",
      "Perceptron Model Accuracy with 100 PCA components: 0.15674603174603174\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Applying PCA with 150 components\n",
      "Perceptron Model Accuracy with 150 PCA components: 0.18968253968253967\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Applying PCA with 200 components\n",
      "Perceptron Model Accuracy with 200 PCA components: 0.19563492063492063\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Applying PCA with 250 components\n",
      "Perceptron Model Accuracy with 250 PCA components: 0.19642857142857142\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Applying PCA with 300 components\n",
      "Perceptron Model Accuracy with 300 PCA components: 0.2123015873015873\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.concatenate([hogFeatures_np, histoFeatures_np], axis=1), image_labels, test_size=0.2, random_state=42)\n",
    "for n_components in range(50, 301, 50):\n",
    "    print(f\"Applying PCA with {n_components} components\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    perceptron_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "    perceptron_model.fit(X_train_pca, y_train)\n",
    "    y_pred = perceptron_model.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Perceptron Model Accuracy with {n_components} PCA components: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model Accuracy: 0.23095238095238096\n",
      "Classification Report for Perceptron:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.22      0.05      0.08       173\n",
      "          clapping       0.24      0.34      0.28       160\n",
      "           cycling       0.29      0.44      0.35       186\n",
      "           dancing       0.38      0.19      0.26       180\n",
      "          drinking       0.10      0.14      0.12       152\n",
      "            eating       0.48      0.17      0.25       151\n",
      "          fighting       0.47      0.23      0.31       186\n",
      "           hugging       0.15      0.15      0.15       151\n",
      "          laughing       0.28      0.28      0.28       179\n",
      "listening_to_music       0.18      0.07      0.10       176\n",
      "           running       0.33      0.35      0.34       155\n",
      "           sitting       0.22      0.26      0.24       163\n",
      "          sleeping       0.39      0.17      0.24       162\n",
      "           texting       0.12      0.36      0.18       183\n",
      "      using_laptop       0.26      0.22      0.24       163\n",
      "\n",
      "          accuracy                           0.23      2520\n",
      "         macro avg       0.27      0.23      0.23      2520\n",
      "      weighted avg       0.27      0.23      0.23      2520\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Naive Bayes Model Accuracy: 0.12420634920634921\n",
      "Classification Report for Naive Bayes:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.08      0.08      0.08       173\n",
      "          clapping       0.14      0.04      0.06       160\n",
      "           cycling       0.29      0.10      0.15       186\n",
      "           dancing       0.23      0.11      0.14       180\n",
      "          drinking       0.11      0.03      0.04       152\n",
      "            eating       0.19      0.13      0.15       151\n",
      "          fighting       0.20      0.19      0.19       186\n",
      "           hugging       0.16      0.07      0.10       151\n",
      "          laughing       0.21      0.03      0.05       179\n",
      "listening_to_music       0.18      0.05      0.07       176\n",
      "           running       0.20      0.10      0.14       155\n",
      "           sitting       0.16      0.05      0.08       163\n",
      "          sleeping       0.09      0.78      0.16       162\n",
      "           texting       0.14      0.09      0.11       183\n",
      "      using_laptop       0.16      0.06      0.08       163\n",
      "\n",
      "          accuracy                           0.12      2520\n",
      "         macro avg       0.17      0.12      0.11      2520\n",
      "      weighted avg       0.17      0.12      0.11      2520\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Decision Tree Model Accuracy: 0.16150793650793652\n",
      "Classification Report for Decision Tree:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.11      0.12      0.11       173\n",
      "          clapping       0.12      0.13      0.13       160\n",
      "           cycling       0.25      0.24      0.24       186\n",
      "           dancing       0.21      0.22      0.21       180\n",
      "          drinking       0.09      0.10      0.09       152\n",
      "            eating       0.31      0.34      0.32       151\n",
      "          fighting       0.29      0.22      0.25       186\n",
      "           hugging       0.06      0.07      0.06       151\n",
      "          laughing       0.16      0.16      0.16       179\n",
      "listening_to_music       0.11      0.10      0.10       176\n",
      "           running       0.14      0.15      0.15       155\n",
      "           sitting       0.08      0.09      0.08       163\n",
      "          sleeping       0.21      0.23      0.22       162\n",
      "           texting       0.13      0.11      0.12       183\n",
      "      using_laptop       0.16      0.15      0.16       163\n",
      "\n",
      "          accuracy                           0.16      2520\n",
      "         macro avg       0.16      0.16      0.16      2520\n",
      "      weighted avg       0.16      0.16      0.16      2520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.concatenate([hogFeatures_np, histoFeatures_np], axis=1), image_labels, test_size=0.2, random_state=42)\n",
    "perceptron_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "y_pred_perceptron = perceptron_model.predict(X_test)\n",
    "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
    "print(f\"Perceptron Model Accuracy: {accuracy_perceptron}\")\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Model Accuracy: {accuracy_nb}\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Model Accuracy: {accuracy_dt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Model Accuracy: 0.25277777777777777\n",
      "AdaBoost Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.19      0.20      0.19       173\n",
      "          clapping       0.16      0.12      0.14       160\n",
      "           cycling       0.47      0.49      0.48       186\n",
      "           dancing       0.35      0.39      0.37       180\n",
      "          drinking       0.08      0.07      0.07       152\n",
      "            eating       0.43      0.55      0.48       151\n",
      "          fighting       0.35      0.39      0.37       186\n",
      "           hugging       0.19      0.13      0.16       151\n",
      "          laughing       0.25      0.42      0.31       179\n",
      "listening_to_music       0.13      0.09      0.11       176\n",
      "           running       0.29      0.29      0.29       155\n",
      "           sitting       0.15      0.13      0.14       163\n",
      "          sleeping       0.18      0.18      0.18       162\n",
      "           texting       0.13      0.09      0.11       183\n",
      "      using_laptop       0.19      0.20      0.20       163\n",
      "\n",
      "          accuracy                           0.25      2520\n",
      "         macro avg       0.24      0.25      0.24      2520\n",
      "      weighted avg       0.24      0.25      0.24      2520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "image_labels=np.array(image_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.concatenate([hogFeatures_np, histoFeatures_np,lbpFeatures_np], axis=1), image_labels, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(n_estimators=300, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Model Accuracy: {accuracy_ada}\")\n",
    "print(\"AdaBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ada))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.33690476190476193\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.25      0.19      0.22       173\n",
      "          clapping       0.32      0.22      0.26       160\n",
      "           cycling       0.39      0.60      0.47       186\n",
      "           dancing       0.48      0.51      0.49       180\n",
      "          drinking       0.20      0.12      0.15       152\n",
      "            eating       0.32      0.76      0.45       151\n",
      "          fighting       0.36      0.49      0.41       186\n",
      "           hugging       0.28      0.12      0.17       151\n",
      "          laughing       0.35      0.39      0.37       179\n",
      "listening_to_music       0.26      0.13      0.17       176\n",
      "           running       0.40      0.34      0.37       155\n",
      "           sitting       0.34      0.11      0.17       163\n",
      "          sleeping       0.37      0.41      0.39       162\n",
      "           texting       0.28      0.22      0.25       183\n",
      "      using_laptop       0.29      0.40      0.34       163\n",
      "\n",
      "          accuracy                           0.34      2520\n",
      "         macro avg       0.32      0.33      0.31      2520\n",
      "      weighted avg       0.33      0.34      0.31      2520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import cv2\n",
    "\n",
    "image_labels=np.array(image_labels)\n",
    "combined_features = np.concatenate([hogFeatures_np, histoFeatures_np,lbpFeatures_np], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, image_labels, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(random_state=42,n_estimators=300,min_samples_leaf=2,min_samples_split=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest_36_hog_histo_lbp.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 5\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mrf_model\u001b[49m, file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "with open('RandomForest_36_hog_histo_lbp.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest_36_hog_histo_lbp.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Accuracy and Classification Report\u001b[39;00m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('RandomForest_36_hog_histo_lbp.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Model Accuracy: 0.34563492063492063\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.23      0.21      0.22       173\n",
      "          clapping       0.38      0.29      0.33       160\n",
      "           cycling       0.43      0.61      0.50       186\n",
      "           dancing       0.48      0.42      0.45       180\n",
      "          drinking       0.26      0.11      0.16       152\n",
      "            eating       0.34      0.81      0.47       151\n",
      "          fighting       0.39      0.52      0.44       186\n",
      "           hugging       0.22      0.13      0.16       151\n",
      "          laughing       0.33      0.34      0.34       179\n",
      "listening_to_music       0.34      0.18      0.24       176\n",
      "           running       0.40      0.33      0.36       155\n",
      "           sitting       0.29      0.17      0.21       163\n",
      "          sleeping       0.37      0.44      0.40       162\n",
      "           texting       0.30      0.20      0.24       183\n",
      "      using_laptop       0.28      0.40      0.33       163\n",
      "\n",
      "          accuracy                           0.35      2520\n",
      "         macro avg       0.33      0.34      0.32      2520\n",
      "      weighted avg       0.34      0.35      0.33      2520\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import cv2\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(combined_features, image_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300} :30\n",
    "# {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300} : 30 smote pca\n",
    "# {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300} : 0.34563492063492063 smote \n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.4142857142857143\n",
      "Ensemble Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           calling       0.22      0.18      0.20       173\n",
      "          clapping       0.45      0.39      0.42       160\n",
      "           cycling       0.60      0.68      0.64       186\n",
      "           dancing       0.54      0.54      0.54       180\n",
      "          drinking       0.25      0.26      0.25       152\n",
      "            eating       0.48      0.74      0.58       151\n",
      "          fighting       0.52      0.53      0.52       186\n",
      "           hugging       0.34      0.29      0.32       151\n",
      "          laughing       0.43      0.42      0.43       179\n",
      "listening_to_music       0.30      0.25      0.27       176\n",
      "           running       0.46      0.45      0.46       155\n",
      "           sitting       0.37      0.29      0.33       163\n",
      "          sleeping       0.44      0.48      0.46       162\n",
      "           texting       0.30      0.25      0.27       183\n",
      "      using_laptop       0.36      0.44      0.39       163\n",
      "\n",
      "          accuracy                           0.41      2520\n",
      "         macro avg       0.40      0.41      0.40      2520\n",
      "      weighted avg       0.41      0.41      0.41      2520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# import cv2\n",
    "# https://www.geeksforgeeks.org/ml-voting-classifier-using-sklearn/\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "combined_features2 = np.concatenate([hogFeatures_np, histoFeatures_np,lbpFeatures_np], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features2, image_labels, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(random_state=42, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, n_estimators=300, learning_rate=0.1, max_depth=6)\n",
    "ensemble_model = VotingClassifier(estimators=[('rf', rf_model), ('xgb', xgb_model)], voting='soft')\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(\"Ensemble Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "with open('42_rf_xbBoost__hog_histo_lbp.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
